# Introduction to this script----
# This script accomplishes several goals:
# 1st - it handles importing your kallisto quantification data into R
# 2nd - this script introduces us to basic tools for annotation
# 3rd - it uses Sleuth to identify differentially expressed genes or transcripts directly from the Kallisto output
# A minimal representation of this script is contained in the last code chunk called 'the essentials'.

# load packages ----
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
library(biomaRt) # for annotation
library(sleuth) #for rapid and simple differential gene expression analysis
library(beepr) #just for fun

# read in your study design ----
#there are LOTS of ways to read data into R, but the readr package (from tidyverse) is one of the simplest
targets <- read_tsv("../../studyDesign.txt")

# you can easily create file paths to the abundance files generated by Kallisto using the 'file.path' function
path <- file.path("../readMapping", targets$sample, "abundance.h5")
# now check to make sure this path is correct by seeing if the files exist
all(file.exists(path)) 
# this should look familiar from your homework
# the functions which(), any() and all() take logical vectors as their argument. The any()
# function will return TRUE if one or more of the elements in the logical vector is TRUE. The all() function
# will return TRUE if every element in the logical vector is TRUE.

# use dplyr to modify your study design to include these file paths as a new column.  
# Sleuth looks for this column, which must be called 'path', in order to locate the data output from Kallisto
targets <- mutate(targets, path)

# get annotations using BiomaRt----
listMarts() #default host is ensembl.org, and most current release of mammalian genomes
#listMarts(host="parasite.wormbase.org") #access to parasite worm genomes
#listMarts(host="protists.ensembl.org") #access to protozoan genomes

#choose the 'mart' you want to work with
myMart <- useMart(biomart="ENSEMBL_MART_ENSEMBL")
#take a look at all available datasets within the selected mart
available.datasets <- listDatasets(myMart)
#now grab the ensembl annotations for human
Hs.anno <- useMart(biomart="ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl")
Hs.filters <- listFilters(Hs.anno)

Tx <- getBM(attributes=c('ensembl_transcript_id_version',
                                     'external_gene_name'),
            mart = Hs.anno)

Tx <- as_tibble(Tx)
#we need to rename the two columns we just retreived from biomart
Tx <- dplyr::rename(Tx, target_id = ensembl_transcript_id_version, gene_name = external_gene_name)

# differential expression analysis using Sleuth ----
# If doing this with your own data, be sure to:
# 1. make the first column of your study design file is called 'sample' and matches the names of your kallisto ouput folders
# 2. if you used Salmon instead of Kallisto for read mapping, you can still use Sleuth but you'll need the Wasabi R package

# Now you're ready to construct a sleuth object
mySleuth.genes <- sleuth_prep(targets, 
                              target_mapping = Tx, #uncomment this line if you want to map transcripts IDs to gene symbols
                              #aggregation_column = 'gene_name', #uncomment this line if you want to collapse your data to gene level
                              read_bootstrap_tpm=TRUE,
                              extra_bootstrap_summary=TRUE) 
beep(sound = 8, expr = NULL)

# fit a linear model to the full data
mySleuth.genes <- sleuth_fit(mySleuth.genes, ~treatment2, 'full')
# What this has accomplished is to “smooth” the raw kallisto abundance estimates for each sample 
# using a linear model with a parameter that represents the experimental condition (naive vs infected)

# for differential expression we must also fit a second 'reduced' model
mySleuth.genes <- sleuth_fit(mySleuth.genes, ~1, 'reduced')
# This tests for transcripts that are differential expressed between the conditions
# by performing a second fit to a “reduced” model that presumes abundances are equal in the two conditions. 
# To identify differential expressed transcripts sleuth will then identify transcripts with a significantly better fit with the “full” model.

# perform a likelihood ratio test (LRT) using the two models above
mySleuth.genes <- sleuth_lrt(mySleuth.genes, 'reduced', 'full')
# NOTE: Sleuth implements a general linear model, 
# so if your provided covariate has more than two levels, 
# it does not perform pairwise comparisons between the samples of different levels. 
# It instead tells you the overall effect of changing the level on expression level. 
# If you are interested in pairwise comparisons, better to use TxImport to read this data into R and use DESeq2 or Limma/VOOM

# now launch an interactive shiny app to explore the results
sleuth_live(mySleuth.genes)


# import Kallisto transcript counts into R using Tximport ----
# copy the abundance files to the working directory and rename so that each sample has a unique name
Txi_gene <- tximport(path, 
                     type = "kallisto", 
                     tx2gene = Tx, 
                     txOut = FALSE, #How does the result change if this =FALSE vs =TRUE?
                     countsFromAbundance = "lengthScaledTPM")

#take a look at the type of object you just created
class(Txi_gene)
names(Txi_gene)

myCPM <- as_tibble(Txi_gene$abundance, rownames = "geneSymbol") # these are you counts after adjusting for transcript length
myCounts <- as_tibble(Txi_gene$counts, rownames = "geneSymbol") # these are your transcript per million (TPM) values, or counts per million (CPM) if you collapsed data to gene level

# #if you exported transcript level data and want to append your gene symbols to the data frame
# Txi_trans <- as_tibble(Txi_trans$counts, rownames = "target_id")
# Txi_trans <- left_join(Txi_trans, Tx)

# the essentials ----
# this chunk contains the minimal essential code from this script
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
library(biomaRt) # provides access to a wealth of annotation info
targets <- read_tsv("../../studyDesign.txt")# read in your study design
path <- file.path("../readMapping", targets$sample, "abundance.h5") # set file paths to your mapped data
targets <- mutate(targets, path) # add paths to your study design (only necessary for Sleuth)
Hs.anno <- useMart(biomart="ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl") # select 'mart' from biomaRt for annotations
Tx <- getBM(attributes=c('ensembl_transcript_id_version', # get gene symbols for each transcript ID
                         'external_gene_name'),
            mart = Hs.anno)
Tx <- as_tibble(Tx) # convert this annotation mapping file to a tibble (the tidyverse version of a dataframe)
Txi_gene <- tximport(path, #reading kallisto data into R
                     type = "kallisto", 
                     tx2gene = Tx, 
                     txOut = FALSE, 
                     countsFromAbundance = "lengthScaledTPM")
myCPM <- as_tibble(Txi_gene$abundance, rownames = "geneSymbol") # these are you counts after adjusting for transcript length
myCounts <- as_tibble(Txi_gene$counts, rownames = "geneSymbol") # these are your transcript per million (TPM) values, or counts per million (CPM) if you collapsed data to gene level
